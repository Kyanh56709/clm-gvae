{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e93f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, StandardScaler, MultiLabelBinarizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "#from sklearn.neighbors import kneighbors_graph\n",
    "import torch_geometric.data as geo_data\n",
    "from tqdm import tqdm \n",
    "\n",
    "# --- File Paths (as provided) ---\n",
    "clinical_csv_path = '../kyanh/data/clinical_features_tmb.csv'\n",
    "radiology_csv_path = '../kyanh/data/radiology_node_features.parquet'\n",
    "pathology_glcm_csv_path= '../kyanh/data/patient_glcm_features.csv'\n",
    "\n",
    "output_multi_view_data_path = 'multi_view_pdl1_data_lesions_366_thresh_08_robust.pt' # Modified output name\n",
    "\n",
    "# --- Feature Definitions (as provided) ---\n",
    "patient_core_features = [\n",
    "    'albumin', 'smoking_status', 'pack_years', 'dnlr', 'age', 'sex', 'TMB',\n",
    "    'histo', 'ecog', 'io_drug', 'pdl1_tiss_site', 'clinical_pdl1_score',\n",
    "    'tumor_burden', \n",
    "]\n",
    "numerical_cols_patient = [\n",
    "    'albumin', 'pack_years', 'dnlr', 'age', 'TMB', 'clinical_pdl1_score', 'tumor_burden', \n",
    "]\n",
    "categorical_cols_patient = [\n",
    "    'smoking_status', 'sex', 'histo', 'ecog', 'pdl1_tiss_site', 'io_drug'\n",
    "]\n",
    "\n",
    "# --- Patient Similarity Parameters ---\n",
    "SIMILARITY_THRESHOLD = 0.7\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "print(\"--- 1. Loading Data ---\")\n",
    "df_clinical_raw = pd.read_csv(clinical_csv_path, index_col='main_index')\n",
    "#df_clinical_raw = df_clinical_raw[df_clinical_raw['TMB'].notna()].copy()\n",
    "\n",
    "df_radiology_lesions_raw = pd.read_parquet(radiology_csv_path)\n",
    "df_radiology_lesions_raw = df_radiology_lesions_raw.reset_index()\n",
    "if 'main_index' in df_radiology_lesions_raw.columns and df_radiology_lesions_raw.index.name != 'main_index':\n",
    "    df_radiology_lesions_raw = df_radiology_lesions_raw.set_index('main_index')\n",
    "elif df_radiology_lesions_raw.index.name != 'main_index':\n",
    "    potential_pid_cols = [col for col in ['main_index', 'patient_id', 'dmp_pt_id'] if col in df_radiology_lesions_raw.columns]\n",
    "    if potential_pid_cols:\n",
    "        print(f\"   Radiology: Setting index to '{potential_pid_cols[0]}'. Ensure this is patient ID.\")\n",
    "        df_radiology_lesions_raw = df_radiology_lesions_raw.set_index(potential_pid_cols[0])\n",
    "    else:\n",
    "        raise ValueError(\"Radiology data needs a 'main_index' or identifiable patient ID column to be set as index.\")\n",
    "\n",
    "\n",
    "df_path_glcm_raw = pd.read_csv(pathology_glcm_csv_path, index_col='main_index')\n",
    "\n",
    "if df_clinical_raw.index.is_unique:\n",
    "    patient_order = df_clinical_raw.index.tolist()\n",
    "else:\n",
    "    print(\"Warning: Clinical data index is not unique. Using unique values for order.\")\n",
    "    patient_order = df_clinical_raw.index.unique().tolist()\n",
    "df_clinical = df_clinical_raw.loc[patient_order].copy() # Main df_clinical is ordered and unique\n",
    "\n",
    "\n",
    "def process_features_dataframe(df_features, numerical_cols, categorical_cols, patient_order_ref, scaler_type=RobustScaler):\n",
    "    df_processed_list = []\n",
    "    df_copy = df_features.copy()\n",
    "\n",
    "    # Imputation: Numerical\n",
    "    for col in numerical_cols:\n",
    "        if col in df_copy.columns:\n",
    "            if df_copy[col].isnull().any():\n",
    "                df_copy[col].fillna(df_copy[col].median(), inplace=True)\n",
    "\n",
    "    # Imputation: Categorical (single-label)\n",
    "    single_label_categorical_cols = list(dict.fromkeys([c for c in categorical_cols if c != 'io_drug']))\n",
    "\n",
    "    for col in single_label_categorical_cols:\n",
    "        if col in df_copy.columns:\n",
    "            df_copy[col] = df_copy[col].astype(str) \n",
    "            valid_entries_mask = ~((df_copy[col].str.lower() == 'nan') | (df_copy[col].str.strip() == ''))\n",
    "            if valid_entries_mask.sum() > 0: \n",
    "                mode_val = df_copy[col][valid_entries_mask].mode()\n",
    "                fill_val = mode_val[0] if not mode_val.empty else 'Unknown'\n",
    "            else: \n",
    "                fill_val = 'Unknown'\n",
    "\n",
    "\n",
    "            df_copy.loc[~valid_entries_mask, col] = fill_val\n",
    "\n",
    "\n",
    "    unique_numerical_cols = list(dict.fromkeys(numerical_cols))\n",
    "    df_num_subset = df_copy[[col for col in unique_numerical_cols if col in df_copy.columns]]\n",
    "    if not df_num_subset.empty:\n",
    "        scaler = scaler_type()\n",
    "        scaled_num = scaler.fit_transform(df_num_subset)\n",
    "        df_scaled_num = pd.DataFrame(scaled_num, columns=df_num_subset.columns, index=df_copy.index)\n",
    "        df_processed_list.append(df_scaled_num)\n",
    "\n",
    "    if 'io_drug' in categorical_cols and 'io_drug' in df_copy.columns:\n",
    "        def split_drugs(drug_value):\n",
    "            if pd.isna(drug_value): return []\n",
    "            s_drug_value = str(drug_value).strip()\n",
    "            if not s_drug_value or s_drug_value.lower() == 'nan': return []\n",
    "            return [drug.strip() for drug in s_drug_value.split(',')]\n",
    "        io_drug_labels = df_copy['io_drug'].apply(split_drugs)\n",
    "        if any(io_drug_labels):\n",
    "            mlb = MultiLabelBinarizer(sparse_output=False)\n",
    "            encoded_io_drug = mlb.fit_transform(io_drug_labels)\n",
    "            if mlb.classes_.size > 0:\n",
    "                sanitized_classes = [cls.replace(\" \", \"_\").replace(\",\", \"\").replace(\"(\", \"\").replace(\")\", \"\") for cls in mlb.classes_]\n",
    "                df_encoded_io_drug = pd.DataFrame(encoded_io_drug, columns=[f'io_drug_{cls}' for cls in sanitized_classes], index=df_copy.index)\n",
    "                df_processed_list.append(df_encoded_io_drug)\n",
    "            else: print(\"   Warning: 'io_drug' binarization no features.\")\n",
    "        else: print(\"   Warning: 'io_drug' column no parsable drug names.\")\n",
    "\n",
    "    cols_for_ohe = [col for col in single_label_categorical_cols if col in df_copy.columns]\n",
    "    if cols_for_ohe:\n",
    "        df_other_cat_subset = df_copy[cols_for_ohe]\n",
    "        encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        encoded_cat = encoder.fit_transform(df_other_cat_subset)\n",
    "        try: feature_names = encoder.get_feature_names_out(df_other_cat_subset.columns)\n",
    "        except AttributeError: feature_names = encoder.get_feature_names(df_other_cat_subset.columns)\n",
    "        df_encoded_cat = pd.DataFrame(encoded_cat, columns=feature_names, index=df_other_cat_subset.index)\n",
    "        df_processed_list.append(df_encoded_cat)\n",
    "\n",
    "    if df_processed_list:\n",
    "        df_final_processed = pd.concat(df_processed_list, axis=1)\n",
    "        return df_final_processed.reindex(patient_order_ref).fillna(0)\n",
    "    return pd.DataFrame(index=patient_order_ref)\n",
    "\n",
    "def create_similarity_edges(df_features_for_sim, patient_idx_map, threshold, edge_type_name, data_obj):\n",
    "    if df_features_for_sim.empty or df_features_for_sim.shape[1] == 0:\n",
    "        print(f\"   Skipping {edge_type_name} similarity: no features.\")\n",
    "        return\n",
    "\n",
    "    valid_rows_mask = ~df_features_for_sim.isnull().all(axis=1)\n",
    "    df_filtered_for_nan_rows = df_features_for_sim[valid_rows_mask]\n",
    "\n",
    "    relevant_patient_orig_ids = [pid for pid in df_filtered_for_nan_rows.index if pid in patient_idx_map]\n",
    "\n",
    "    if not relevant_patient_orig_ids:\n",
    "        print(f\"   Skipping {edge_type_name} similarity: no relevant patients with non-NaN features after filtering.\")\n",
    "        return\n",
    "\n",
    "    df_subset_features = df_filtered_for_nan_rows.loc[relevant_patient_orig_ids].fillna(0)\n",
    "\n",
    "    if df_subset_features.shape[0] <= 1: # Need at least 2 patients to form an edge\n",
    "        print(f\"   Skipping {edge_type_name} similarity: not enough samples ({df_subset_features.shape[0]}) to form edges.\")\n",
    "        return\n",
    "\n",
    "    subset_global_indices_map = {orig_id: patient_idx_map[orig_id] for orig_id in relevant_patient_orig_ids}\n",
    "    \n",
    "    print(f\"   Calculating {edge_type_name} patient similarity (Cosine Sim > {threshold}) for {df_subset_features.shape[0]} patients with {df_subset_features.shape[1]} features...\")\n",
    "    try:\n",
    "        features_values = df_subset_features.values\n",
    "        \n",
    "        pairwise_sim_matrix = cosine_similarity(features_values) # Returns a NumPy array\n",
    "        \n",
    "\n",
    "        np.fill_diagonal(pairwise_sim_matrix, -np.inf) \n",
    "        \n",
    "        src_nodes_local_indices, dst_nodes_local_indices = np.where(pairwise_sim_matrix > threshold)\n",
    "        \n",
    "        if src_nodes_local_indices.size == 0:\n",
    "            print(f\"   No {edge_type_name} edges found above similarity threshold {threshold}.\")\n",
    "            return\n",
    "            \n",
    "        # Get the similarity scores for these edges\n",
    "        edge_attr_scores = pairwise_sim_matrix[src_nodes_local_indices, dst_nodes_local_indices]\n",
    "\n",
    "        original_ids_in_subset_order = df_subset_features.index\n",
    "        \n",
    "        global_src_indices = torch.tensor(\n",
    "            [subset_global_indices_map[original_ids_in_subset_order[local_idx]] for local_idx in src_nodes_local_indices],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        global_dst_indices = torch.tensor(\n",
    "            [subset_global_indices_map[original_ids_in_subset_order[local_idx]] for local_idx in dst_nodes_local_indices],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        \n",
    "        filtered_edge_index_global = torch.stack([global_src_indices, global_dst_indices], dim=0)\n",
    "        filtered_edge_attr_subset = torch.tensor(edge_attr_scores, dtype=torch.float32).unsqueeze(1)\n",
    "        \n",
    "        num_kept_edges = filtered_edge_index_global.shape[1]\n",
    "        print(f\"   Created {num_kept_edges} {edge_type_name} edges based on similarity > {threshold}.\")\n",
    "\n",
    "        if num_kept_edges > 0:\n",
    "            data_obj['patient', edge_type_name, 'patient'].edge_index = filtered_edge_index_global\n",
    "            data_obj['patient', edge_type_name, 'patient'].edge_attr = filtered_edge_attr_subset\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   Error calculating similarity for {edge_type_name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "# --- Global Patient Index Mapping ---\n",
    "patient_to_global_idx = {pid: i for i, pid in enumerate(patient_order)}\n",
    "num_total_patients = len(patient_order)\n",
    "\n",
    "# --- Initialize HeteroData ---\n",
    "data = geo_data.HeteroData()\n",
    "data['patient'].num_nodes = num_total_patients\n",
    "\n",
    "# --- 2. Clinical View ---\n",
    "print(\"\\n--- 2. Preparing Clinical View ---\")\n",
    "available_patient_core_features = [col for col in patient_core_features if col in df_clinical.columns]\n",
    "current_numerical_cols_patient = [col for col in numerical_cols_patient if col in available_patient_core_features]\n",
    "current_categorical_cols_patient = [col for col in categorical_cols_patient if col in available_patient_core_features]\n",
    "df_patient_clinical_processed = process_features_dataframe(\n",
    "    df_clinical[available_patient_core_features].copy(), \n",
    "    current_numerical_cols_patient,\n",
    "    current_categorical_cols_patient,\n",
    "    patient_order\n",
    ")\n",
    "if not df_patient_clinical_processed.empty and df_patient_clinical_processed.shape[1] > 0:\n",
    "    data['patient'].x_clinical = torch.tensor(df_patient_clinical_processed.values, dtype=torch.float32)\n",
    "    print(f\"   Assigned 'patient.x_clinical' features: {data['patient'].x_clinical.shape}\")\n",
    "    create_similarity_edges(df_patient_clinical_processed, patient_to_global_idx, SIMILARITY_THRESHOLD, 'similar_to_clinical', data)\n",
    "else:\n",
    "    print(\"   No clinical features. Clinical view features will be empty.\")\n",
    "    data['patient'].x_clinical = torch.empty((num_total_patients, 0), dtype=torch.float32)\n",
    "\n",
    "\n",
    "# --- 3. Pathology View ---\n",
    "print(\"\\n--- 3. Preparing Pathology View ---\")\n",
    "df_path_glcm_subset = df_path_glcm_raw.drop(columns=['dmp_pt_id'], errors='ignore').copy()\n",
    "df_path_glcm_subset = df_path_glcm_subset[df_path_glcm_subset.index.isin(patient_order)]\n",
    "\n",
    "if not df_path_glcm_subset.empty:\n",
    "    glcm_numerical_cols = df_path_glcm_subset.columns.tolist()\n",
    "    df_path_glcm_processed_full = process_features_dataframe(\n",
    "        df_path_glcm_subset.copy(),\n",
    "        glcm_numerical_cols, [], patient_order \n",
    "    )\n",
    "    data['patient'].x_pathology = torch.tensor(df_path_glcm_processed_full.values, dtype=torch.float32)\n",
    "    pathology_present_mask = torch.zeros(num_total_patients, dtype=torch.bool)\n",
    "    for orig_id in df_path_glcm_subset.index:\n",
    "        if orig_id in patient_to_global_idx:\n",
    "            pathology_present_mask[patient_to_global_idx[orig_id]] = True\n",
    "    data['patient'].pathology_mask = pathology_present_mask\n",
    "    print(f\"   Assigned 'patient.x_pathology' (zero-padded for all patients): {data['patient'].x_pathology.shape}\")\n",
    "    print(f\"   Number of patients with actual pathology data: {pathology_present_mask.sum().item()}\")\n",
    "\n",
    "    df_path_glcm_scaled_for_sim = process_features_dataframe(\n",
    "        df_path_glcm_subset.copy(), # patients with pathology data\n",
    "        glcm_numerical_cols, [],\n",
    "        df_path_glcm_subset.index.tolist()\n",
    "    )\n",
    "    create_similarity_edges(df_path_glcm_scaled_for_sim, patient_to_global_idx, SIMILARITY_THRESHOLD, 'similar_to_pathology', data)\n",
    "else:\n",
    "    print(\"   No Pathology GLCM features.\")\n",
    "    data['patient'].x_pathology = torch.zeros((num_total_patients, 0), dtype=torch.float32)\n",
    "    data['patient'].pathology_mask = torch.zeros(num_total_patients, dtype=torch.bool)\n",
    "\n",
    "\n",
    "# --- 4. Radiology View (Lesion-Level) ---\n",
    "print(\"\\n--- 4. Preparing Radiology View (Lesion-Level) ---\")\n",
    "exclude_rad_cols = ['radiology_accession_number', 'job_tag', 'dmp_pt_id']\n",
    "all_radiomics_feature_cols = [col for col in df_radiology_lesions_raw.columns if col not in exclude_rad_cols]\n",
    "\n",
    "df_radiology_lesions_filtered = df_radiology_lesions_raw[df_radiology_lesions_raw.index.isin(patient_order)].copy()\n",
    "\n",
    "if not df_radiology_lesions_filtered.empty and all_radiomics_feature_cols:\n",
    "    df_lesion_features_to_scale = df_radiology_lesions_filtered[all_radiomics_feature_cols].copy()\n",
    "    for col in all_radiomics_feature_cols:\n",
    "        df_lesion_features_to_scale[col] = pd.to_numeric(df_lesion_features_to_scale[col], errors='coerce')\n",
    "\n",
    "    for col in all_radiomics_feature_cols:\n",
    "        if df_lesion_features_to_scale[col].isnull().any():\n",
    "            df_lesion_features_to_scale[col].fillna(df_lesion_features_to_scale[col].median(), inplace=True)\n",
    "\n",
    "    scaler_lesions = RobustScaler()\n",
    "    scaled_lesion_features_values = scaler_lesions.fit_transform(df_lesion_features_to_scale)\n",
    "    df_radiology_scaled_lesions = pd.DataFrame(\n",
    "        scaled_lesion_features_values,\n",
    "        columns=all_radiomics_feature_cols,\n",
    "        index=df_lesion_features_to_scale.index \n",
    "    )\n",
    "    print(f\"   Scaled {df_radiology_scaled_lesions.shape[1]} features for {df_radiology_scaled_lesions.shape[0]} lesions.\")\n",
    "\n",
    "    all_lesion_x_list = []\n",
    "    patient_lesion_edge_src = []\n",
    "    patient_lesion_edge_dst = []\n",
    "    current_lesion_global_idx = 0\n",
    "    radiology_present_mask_np = np.zeros(num_total_patients, dtype=bool)\n",
    "    temp_aggregated_radiology_features = {} \n",
    "\n",
    "    for patient_orig_id in tqdm(patient_order, desc=\"Processing lesions per patient\"):\n",
    "        if patient_orig_id in df_radiology_scaled_lesions.index:\n",
    "            patient_global_idx = patient_to_global_idx[patient_orig_id]\n",
    "            lesions_for_patient_df = df_radiology_scaled_lesions.loc[[patient_orig_id]]\n",
    "\n",
    "            if not lesions_for_patient_df.empty:\n",
    "                radiology_present_mask_np[patient_global_idx] = True\n",
    "                all_lesion_x_list.append(torch.tensor(lesions_for_patient_df.values, dtype=torch.float32))\n",
    "                num_lesions_this_patient = lesions_for_patient_df.shape[0]\n",
    "                \n",
    "                patient_lesion_edge_src.extend([patient_global_idx] * num_lesions_this_patient)\n",
    "                patient_lesion_edge_dst.extend(list(range(current_lesion_global_idx, current_lesion_global_idx + num_lesions_this_patient)))\n",
    "                current_lesion_global_idx += num_lesions_this_patient\n",
    "\n",
    "                patient_lesion_mean = lesions_for_patient_df.mean(axis=0)\n",
    "                if num_lesions_this_patient > 1:\n",
    "                    patient_lesion_std = lesions_for_patient_df.std(axis=0)\n",
    "                else:\n",
    "\n",
    "                    patient_lesion_std = pd.Series(0.0, index=patient_lesion_mean.index, dtype=float)\n",
    "                patient_lesion_min = lesions_for_patient_df.min(axis=0)\n",
    "                patient_lesion_max = lesions_for_patient_df.max(axis=0)\n",
    "\n",
    "                # Concat\n",
    "                aggregated_stats_for_patient = pd.concat([\n",
    "                    patient_lesion_mean,\n",
    "                    patient_lesion_std,\n",
    "                    patient_lesion_min,\n",
    "                    patient_lesion_max\n",
    "                ]).values # .values converts\n",
    "                \n",
    "                temp_aggregated_radiology_features[patient_orig_id] = aggregated_stats_for_patient\n",
    "\n",
    "    if all_lesion_x_list:\n",
    "        data['lesion'].x = torch.cat(all_lesion_x_list, dim=0)\n",
    "        data['lesion'].num_nodes = data['lesion'].x.shape[0]\n",
    "        edge_index_patient_lesion = torch.tensor([patient_lesion_edge_src, patient_lesion_edge_dst], dtype=torch.long)\n",
    "        data['patient', 'has_lesion', 'lesion'].edge_index = edge_index_patient_lesion\n",
    "        print(f\"   Assigned 'lesion.x' features: {data['lesion'].x.shape}\")\n",
    "        print(f\"   Created ('patient', 'has_lesion', 'lesion') edges: {edge_index_patient_lesion.shape}\")\n",
    "    else:\n",
    "        print(\"   No lesions found for any patient in the order.\")\n",
    "        data['lesion'].x = torch.empty((0, len(all_radiomics_feature_cols) if all_radiomics_feature_cols else 0), dtype=torch.float32)\n",
    "        data['lesion'].num_nodes = 0\n",
    "        data['patient', 'has_lesion', 'lesion'].edge_index = torch.empty((2,0), dtype=torch.long)\n",
    "\n",
    "    data['patient'].radiology_mask = torch.from_numpy(radiology_present_mask_np)\n",
    "    print(f\"   Number of patients with actual radiology (lesion) data: {data['patient'].radiology_mask.sum().item()}\")\n",
    "\n",
    "    if temp_aggregated_radiology_features:\n",
    "        \n",
    "        new_radiology_agg_cols = []\n",
    "        if all_radiomics_feature_cols:\n",
    "            suffixes = ['mean', 'std', 'min', 'max']\n",
    "            for stat_suffix in suffixes:\n",
    "                new_radiology_agg_cols.extend([f\"{col}_{stat_suffix}\" for col in all_radiomics_feature_cols])\n",
    "        \n",
    "        df_temp_aggregated_radiology = pd.DataFrame.from_dict(\n",
    "            temp_aggregated_radiology_features,\n",
    "            orient='index',\n",
    "            columns=new_radiology_agg_cols \n",
    "        )\n",
    "        \n",
    "        if not df_temp_aggregated_radiology.empty and df_temp_aggregated_radiology.shape[1] > 0:\n",
    "            print(f\"   Aggregated radiology features for similarity (mean, std, min, max) shape: {df_temp_aggregated_radiology.shape}\")\n",
    "            create_similarity_edges(df_temp_aggregated_radiology, patient_to_global_idx, SIMILARITY_THRESHOLD, 'similar_to_radiology', data)\n",
    "        else:\n",
    "            print(\"   Aggregated radiology DataFrame (mean, std, min, max) is empty or has no columns. Skipping similarity graph.\")\n",
    "    else:\n",
    "        print(\"   No temporary aggregated radiology features to build similarity graph.\")\n",
    "\n",
    "else:\n",
    "    print(\"   Radiology lesion data is empty or no radiomics feature columns identified.\")\n",
    "    data['lesion'].x = torch.empty((0, 0), dtype=torch.float32)\n",
    "    data['lesion'].num_nodes = 0\n",
    "    data['patient', 'has_lesion', 'lesion'].edge_index = torch.empty((2,0), dtype=torch.long)\n",
    "    data['patient'].radiology_mask = torch.zeros(num_total_patients, dtype=torch.bool)\n",
    "\n",
    "\n",
    "# --- 5. Add Patient Labels (Common to all patients) ---\n",
    "print(\"\\n--- 5. Adding Patient Labels ---\")\n",
    "label_cols_to_add = {'pfs': 'y', 'pfs_censor': 'event', 'label': 'binary_label'}\n",
    "df_labels_ordered = df_clinical.reindex(patient_order)\n",
    "for col_name, data_attr_name in label_cols_to_add.items():\n",
    "    if col_name in df_labels_ordered.columns:\n",
    "        try:\n",
    "            if df_labels_ordered[col_name].isnull().all():\n",
    "                print(f\"   Warning: Label column '{col_name}' is all NaN. Skipping.\")\n",
    "                continue\n",
    "            if data_attr_name == 'y': \n",
    "                tensor_data = torch.tensor(df_labels_ordered[col_name].fillna(np.nan).values, dtype=torch.float32)\n",
    "\n",
    "            else: \n",
    "                filled_series = df_labels_ordered[col_name].fillna(0) \n",
    "                tensor_data = torch.tensor(filled_series.values, dtype=torch.long)\n",
    "\n",
    "            data['patient'][data_attr_name] = tensor_data\n",
    "            print(f\"   Added label '{data_attr_name}' from column '{col_name}'. Shape: {tensor_data.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   Warning: Could not process or add label '{data_attr_name}': {e}\")\n",
    "    else:\n",
    "        print(f\"   Warning: Label column '{col_name}' not found.\")\n",
    "\n",
    "\n",
    "# --- Final Checks and Save ---\n",
    "print(f\"\\n--- Multi-View HeteroData Summary ---\")\n",
    "print(data)\n",
    "try:\n",
    "    data.validate(raise_on_error=True)\n",
    "    print(\"Multi-View Data validation successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Multi-View Data validation FAILED: {e}\")\n",
    "\n",
    "print(\"\\nNode Types and Features:\")\n",
    "for node_type in data.node_types:\n",
    "    print(f\"  Node type: {node_type}\")\n",
    "    for key, value in data[node_type].items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            print(f\"    {key}: shape {value.shape}, num_nodes (implicit from dim 0): {value.shape[0] if value.dim() > 0 else 'N/A'}\")\n",
    "        else:\n",
    "            print(f\"    {key}: {value}\")\n",
    "\n",
    "\n",
    "print(\"\\nEdge Types and Indices:\")\n",
    "if hasattr(data, 'edge_types'):\n",
    "    for edge_type in sorted(data.edge_types, key=lambda x: str(x)):\n",
    "        edge_index = data[edge_type].get('edge_index', None)\n",
    "        shape_str = str(edge_index.shape) if edge_index is not None else 'N/A'\n",
    "        num_edges_str = str(edge_index.shape[1]) if edge_index is not None and edge_index.dim() == 2 else '0'\n",
    "        print(f\"  {str(edge_type)}: edge_index shape: {shape_str} ({num_edges_str} edges)\", end=\"\")\n",
    "        edge_attr = data[edge_type].get('edge_attr', None)\n",
    "        if edge_attr is not None:\n",
    "             print(f\", edge_attr shape: {edge_attr.shape}\")\n",
    "        else:\n",
    "             print(\"\")\n",
    "else:\n",
    "    print(\"  No edge types defined in data object.\")\n",
    "\n",
    "\n",
    "try:\n",
    "    torch.save(data, output_multi_view_data_path)\n",
    "    print(f\"\\nSaved Multi-View HeteroData object to {output_multi_view_data_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError saving Multi-View HeteroData object: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
